{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "import requests\n",
    "\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = pyspark.sql.SparkSession.builder.master('local[16]').appName('covid19').config('spark.driver.memory', '8g').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming cwd is repo root.\n",
    "# with open('data/confirmed_mar27_2020.csv', 'rb') as fh:\n",
    "with open('data/confirmed_mar27_2020.csv', 'r') as fh:\n",
    "    confirmed_fc = fh.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file len: 48844\n",
      "rows: 251\n"
     ]
    }
   ],
   "source": [
    "print(f'file len: {len(confirmed_fc)}')\n",
    "rows = confirmed_fc.split('\\n')\n",
    "print(f'rows: {len(rows)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "',Burma,21.9162,95.956,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the last line, just empty row.\n",
    "del rows[250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_rdd = spark.sparkContext.parallelize(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conf_rdd.collect()\n",
    "# conf_rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_rdd_idx = conf_rdd.zipWithIndex().map(lambda rec: (rec[1], rec[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  'Province/State,Country/Region,Lat,Long,1/22/20,1/23/20,1/24/20,1/25/20,1/26/20,1/27/20,1/28/20,1/29/20,1/30/20,1/31/20,2/1/20,2/2/20,2/3/20,2/4/20,2/5/20,2/6/20,2/7/20,2/8/20,2/9/20,2/10/20,2/11/20,2/12/20,2/13/20,2/14/20,2/15/20,2/16/20,2/17/20,2/18/20,2/19/20,2/20/20,2/21/20,2/22/20,2/23/20,2/24/20,2/25/20,2/26/20,2/27/20,2/28/20,2/29/20,3/1/20,3/2/20,3/3/20,3/4/20,3/5/20,3/6/20,3/7/20,3/8/20,3/9/20,3/10/20,3/11/20,3/12/20,3/13/20,3/14/20,3/15/20,3/16/20,3/17/20,3/18/20,3/19/20,3/20/20,3/21/20,3/22/20,3/23/20,3/24/20,3/25/20,3/26/20,3/27/20'),\n",
       " (1,\n",
       "  ',Afghanistan,33.0,65.0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,4,4,5,7,7,7,11,16,21,22,22,22,24,24,40,40,74,84,94,110'),\n",
       " (2,\n",
       "  ',Albania,41.1533,20.1683,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,10,12,23,33,38,42,51,55,59,64,70,76,89,104,123,146,174,186')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_rdd_idx.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * is the splat operator here. similar to spread in js\n",
    "conf_rdd_splat = conf_rdd_idx.map(lambda rec: (rec[0], *(rec[1].split(',')) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conf_rdd_splat.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe is just an rdd + schema, here i am not really specifying much schema\n",
    "conf_df = conf_rdd_splat.toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will look bad if word wrap is enabled.\n",
    "# conf_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+-------------------+-------+-------+-------+-------+-------+-------+-------+-------+\n",
      "| _1|                  _2|                 _3|    _64|    _65|    _66|    _67|    _68|    _69|    _70|    _71|\n",
      "+---+--------------------+-------------------+-------+-------+-------+-------+-------+-------+-------+-------+\n",
      "|  0|      Province/State|     Country/Region|3/20/20|3/21/20|3/22/20|3/23/20|3/24/20|3/25/20|3/26/20|3/27/20|\n",
      "|  1|                    |        Afghanistan|     24|     24|     40|     40|     74|     84|     94|    110|\n",
      "|  2|                    |            Albania|     70|     76|     89|    104|    123|    146|    174|    186|\n",
      "|  3|                    |            Algeria|     90|    139|    201|    230|    264|    302|    367|    409|\n",
      "|  4|                    |            Andorra|     75|     88|    113|    133|    164|    188|    224|    267|\n",
      "|  5|                    |             Angola|      1|      2|      2|      3|      3|      3|      4|      4|\n",
      "|  6|                    |Antigua and Barbuda|      1|      1|      1|      3|      3|      3|      7|      7|\n",
      "|  7|                    |          Argentina|    128|    158|    266|    301|    387|    387|    502|    589|\n",
      "|  8|                    |            Armenia|    136|    160|    194|    235|    249|    265|    290|    329|\n",
      "|  9|Australian Capita...|          Australia|      6|      9|     19|     32|     39|     39|     53|     62|\n",
      "| 10|     New South Wales|          Australia|    353|    436|    669|    669|    818|   1029|   1219|   1405|\n",
      "| 11|  Northern Territory|          Australia|      3|      3|      5|      5|      6|      6|     12|     12|\n",
      "| 12|          Queensland|          Australia|    184|    221|    259|    319|    397|    443|    493|    555|\n",
      "| 13|     South Australia|          Australia|     50|     67|    100|    134|    170|    170|    235|    257|\n",
      "| 14|            Tasmania|          Australia|     10|     16|     22|     28|     28|     36|     47|     47|\n",
      "| 15|            Victoria|          Australia|    121|    229|    355|    355|    411|    466|    520|    574|\n",
      "| 16|   Western Australia|          Australia|     64|     90|    120|    140|    175|    175|    231|    231|\n",
      "| 17|                    |            Austria|   2388|   2814|   3582|   4474|   5283|   5588|   6909|   7657|\n",
      "| 18|                    |         Azerbaijan|     44|     53|     65|     72|     87|     93|    122|    165|\n",
      "| 19|                    |            Bahamas|      3|      4|      4|      4|      5|      5|      9|     10|\n",
      "+---+--------------------+-------------------+-------+-------+-------+-------+-------+-------+-------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# take first 3 columns and the last 8 columns\n",
    "conf_df.select(conf_df.columns[:3] + conf_df.columns[-8:]).show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
